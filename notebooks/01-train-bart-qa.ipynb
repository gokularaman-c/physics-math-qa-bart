{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11127238,"sourceType":"datasetVersion","datasetId":6939482}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# import torch\n# from transformers import T5TokenizerFast, T5ForConditionalGeneration, Trainer, TrainingArguments\n# from datasets import load_dataset\n\n# # Load dataset\n# train_dir = \"/kaggle/input/qa-dataset/dataset/train/train.json\"\n# test_dir = \"/kaggle/input/qa-dataset/dataset/test/test.json\"\n# dataset = load_dataset(\"json\", data_files={\"train\": train_dir, \"validation\": test_dir})\n\n# # Load T5 tokenizer and model\n# tokenizer = T5TokenizerFast.from_pretrained(\"t5-base\")\n# model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n\n# # Define preprocessing function\n# def preprocess_data(examples):\n#     inputs = [f\"question: {q} context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n#     targets = examples[\"answers\"]\n\n#     model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n#     labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n\n#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n#     return model_inputs\n\n# # Apply preprocessing\n# tokenized_datasets = dataset.map(\n#     preprocess_data,\n#     batched=True,\n#     remove_columns=[\"context\", \"question\", \"answers\"]\n# )\n\n# # Move model to GPU if available\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)\n\n# # Training arguments\n# training_args = TrainingArguments(\n#     output_dir=\"./t5_qa\",\n#     eval_strategy=\"steps\",\n#     eval_steps=500,\n#     save_strategy=\"steps\",\n#     save_steps=500,\n#     logging_strategy=\"steps\",\n#     logging_steps=100,\n#     per_device_train_batch_size=2,\n#     per_device_eval_batch_size=2,\n#     gradient_accumulation_steps=2,\n#     num_train_epochs=3,\n#     learning_rate=2e-5,\n#     weight_decay=0.01,\n#     warmup_steps=500,\n#     max_grad_norm=1.0,\n#     report_to=\"none\",\n#     save_total_limit=2,\n#     disable_tqdm=True,\n#     fp16=True,\n#     dataloader_pin_memory=False,\n#     optim=\"adamw_torch\",\n#     bf16=False\n# )\n\n# # Trainer setup\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=tokenized_datasets[\"train\"],\n#     eval_dataset=tokenized_datasets[\"validation\"]\n# )\n\n# # Train the model\n# trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T14:49:25.188634Z","iopub.execute_input":"2025-03-22T14:49:25.189042Z","iopub.status.idle":"2025-03-22T16:24:22.197422Z","shell.execute_reply.started":"2025-03-22T14:49:25.189011Z","shell.execute_reply":"2025-03-22T16:24:22.196548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T18:05:00.555929Z","iopub.execute_input":"2025-03-22T18:05:00.556263Z","iopub.status.idle":"2025-03-22T18:06:21.063768Z","shell.execute_reply.started":"2025-03-22T18:05:00.556237Z","shell.execute_reply":"2025-03-22T18:06:21.062889Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import BartTokenizerFast, BartForConditionalGeneration, Trainer, TrainingArguments\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T14:52:50.054906Z","iopub.execute_input":"2025-03-23T14:52:50.055109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ntrain_dir = \"/kaggle/input/qa-dataset/dataset/train/train.json\"\ntest_dir = \"/kaggle/input/qa-dataset/dataset/test/test.json\"\ndataset = load_dataset(\"json\", data_files={\"train\": train_dir, \"validation\": test_dir})\n\n# Load BART tokenizer and model\ntokenizer = BartTokenizerFast.from_pretrained(\"facebook/bart-large\")\nmodel = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T14:52:50.054906Z","iopub.execute_input":"2025-03-23T14:52:50.055109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define preprocessing function\ndef preprocess_data(examples):\n    inputs = tokenizer(\n        examples[\"question\"],\n        examples[\"context\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=512\n    )\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"answers\"],\n            truncation=True,\n            padding=\"max_length\",\n            max_length=128\n        )\n\n    inputs[\"labels\"] = labels[\"input_ids\"]\n    return inputs\n\n# Apply preprocessing\ntokenized_datasets = dataset.map(\n    preprocess_data,\n    batched=True,\n    remove_columns=[\"context\", \"question\", \"answers\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T14:52:50.054906Z","iopub.execute_input":"2025-03-23T14:52:50.055109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./bart_qa\",\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=500,\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=2,\n    num_train_epochs=3,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    warmup_steps=500,\n    max_grad_norm=1.0,\n    report_to=\"none\",\n    save_total_limit=2,\n    disable_tqdm=True,\n    fp16=True,\n    dataloader_pin_memory=False,\n    optim=\"adamw_torch\",\n    bf16=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T14:52:50.054906Z","iopub.execute_input":"2025-03-23T14:52:50.055109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Trainer setup\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"]\n)\n\n# Train the model\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T14:52:50.054906Z","iopub.execute_input":"2025-03-23T14:52:50.055109Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c6879826b674bd190f2722e807610f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e946596ae66a4123a01caa973773a613"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25e7ad42b9054783b634cc1775a1caf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37b8466ae7a0401f83069ea959abb018"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1fa1e613bac4f93937ec6be1a1b55f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bd6675bba3846ac90c81244402453c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90ad025390914b28a6b26fe00968b9ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e8d97a8f2834a0eb1f80502535f1670"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11018 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19cad6fae1f4ed5b249cff8b8dff9cc"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3953: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2755 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc2b7b98b014a13b4b06eb7bf838292"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 13.0337, 'grad_norm': 4356703.0, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.07259528130671507}\n{'loss': 7.0226, 'grad_norm': 5013011.0, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.14519056261343014}\n{'loss': 4.6303, 'grad_norm': 5462073.0, 'learning_rate': 1.2e-05, 'epoch': 0.2177858439201452}\n{'loss': 1.7432, 'grad_norm': 1898636.375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.29038112522686027}\n{'loss': 0.1498, 'grad_norm': 236059.53125, 'learning_rate': 2e-05, 'epoch': 0.3629764065335753}\n{'eval_loss': 0.06640709936618805, 'eval_runtime': 244.4202, 'eval_samples_per_second': 11.272, 'eval_steps_per_second': 2.819, 'epoch': 0.3629764065335753}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0672, 'grad_norm': 1908899.625, 'learning_rate': 1.9449187551638668e-05, 'epoch': 0.4355716878402904}\n{'loss': 0.0558, 'grad_norm': 696970.75, 'learning_rate': 1.8898375103277335e-05, 'epoch': 0.5081669691470054}\n{'loss': 0.049, 'grad_norm': 1245967.125, 'learning_rate': 1.8347562654916e-05, 'epoch': 0.5807622504537205}\n{'loss': 0.0464, 'grad_norm': 1197801.875, 'learning_rate': 1.7796750206554668e-05, 'epoch': 0.6533575317604355}\n{'loss': 0.1665, 'grad_norm': 190735.03125, 'learning_rate': 1.7245937758193335e-05, 'epoch': 0.7259528130671506}\n{'eval_loss': 0.0580323152244091, 'eval_runtime': 244.2298, 'eval_samples_per_second': 11.28, 'eval_steps_per_second': 2.821, 'epoch': 0.7259528130671506}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0452, 'grad_norm': 138733.84375, 'learning_rate': 1.6695125309832005e-05, 'epoch': 0.7985480943738656}\n{'loss': 0.0483, 'grad_norm': 522915.8125, 'learning_rate': 1.614431286147067e-05, 'epoch': 0.8711433756805808}\n{'loss': 0.039, 'grad_norm': 190414.203125, 'learning_rate': 1.5593500413109338e-05, 'epoch': 0.9437386569872959}\n{'loss': 0.0362, 'grad_norm': 145277.9375, 'learning_rate': 1.5042687964748005e-05, 'epoch': 1.0159709618874773}\n{'loss': 0.0336, 'grad_norm': 166815.390625, 'learning_rate': 1.4491875516386671e-05, 'epoch': 1.0885662431941925}\n{'eval_loss': 0.04493004456162453, 'eval_runtime': 244.0015, 'eval_samples_per_second': 11.291, 'eval_steps_per_second': 2.824, 'epoch': 1.0885662431941925}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0326, 'grad_norm': 136244.875, 'learning_rate': 1.3941063068025338e-05, 'epoch': 1.1611615245009075}\n{'loss': 0.0331, 'grad_norm': 335799.875, 'learning_rate': 1.3390250619664004e-05, 'epoch': 1.2337568058076225}\n{'loss': 0.0307, 'grad_norm': 1400752.125, 'learning_rate': 1.2839438171302671e-05, 'epoch': 1.3063520871143375}\n{'loss': 0.0307, 'grad_norm': 265265.78125, 'learning_rate': 1.228862572294134e-05, 'epoch': 1.3789473684210527}\n{'loss': 0.0309, 'grad_norm': 195410.328125, 'learning_rate': 1.1737813274580006e-05, 'epoch': 1.4515426497277677}\n{'eval_loss': 0.0415491946041584, 'eval_runtime': 244.3209, 'eval_samples_per_second': 11.276, 'eval_steps_per_second': 2.82, 'epoch': 1.4515426497277677}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0286, 'grad_norm': 128632.7890625, 'learning_rate': 1.1187000826218673e-05, 'epoch': 1.524137931034483}\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"save_path = \"/kaggle/working/bart_qa_finetuned\"\ntrainer.save_model(save_path)\ntokenizer.save_pretrained(save_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/bart_qa_finetuned\", 'zip', \"bart_qa_finetuned\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import LEDTokenizer, LEDForConditionalGeneration, Trainer, TrainingArguments\nfrom datasets import load_dataset\n\ntrain_dir = \"/kaggle/input/qa-dataset/dataset/train/train.json\"\ntest_dir = \"/kaggle/input/qa-dataset/dataset/test/test.json\"\ndataset = load_dataset(\"json\", data_files={\"train\": train_dir, \"validation\": test_dir})\n\n# Use the correct model identifier\ntokenizer = LEDTokenizer.from_pretrained(\"allenai/led-base-16384\")\nmodel = LEDForConditionalGeneration.from_pretrained(\"allenai/led-base-16384\")\n\ndef preprocess_data(examples):\n    inputs = [f\"question: {q} context: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n    targets = examples[\"answers\"]\n    model_inputs = tokenizer(inputs, max_length=1024, padding=\"max_length\", truncation=True)\n    labels = tokenizer(targets, max_length=128, padding=\"max_length\", truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_datasets = dataset.map(\n    preprocess_data,\n    batched=True,\n    remove_columns=[\"context\", \"question\", \"answers\"]\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ntraining_args = TrainingArguments(\n    output_dir=\"./led_qa\",\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=500,\n    logging_strategy=\"steps\",\n    logging_steps=100,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=2,\n    num_train_epochs=3,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    warmup_steps=500,\n    max_grad_norm=1.0,\n    report_to=\"none\",\n    save_total_limit=2,\n    disable_tqdm=True,\n    fp16=True,\n    dataloader_pin_memory=False,\n    optim=\"adamw_torch\",\n    bf16=False\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"]\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-28T03:57:08.114984Z","iopub.execute_input":"2025-03-28T03:57:08.115245Z","iopub.status.idle":"2025-03-28T05:09:10.602165Z","shell.execute_reply.started":"2025-03-28T03:57:08.115217Z","shell.execute_reply":"2025-03-28T05:09:10.600394Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec1e8ba032924240907e3e0c80cdf8b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6065475e6ac8490fa57128d24821c99a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9665decc3a0742f9b3d3a5e1412e47c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e1d6a107f3e436ca9d5f62d55c336c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7da33e8349884b40bcfca150495dc7c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e08d89664e44f8886e6deeeae765842"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2884511a6444674b881a15d349cedba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/648M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8611f4a4ffa47828f39be440ffb4efb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4483566156a140fb84077aba9a8078be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11018 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b8ee8f92b94a79b0e3c5890113de62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2755 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a968e3a311648ef9c9df11b619a3c07"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 12.3406, 'grad_norm': 7017768.0, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.07259528130671507}\n{'loss': 5.0122, 'grad_norm': 6689450.0, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.14519056261343014}\n{'loss': 2.2308, 'grad_norm': 4485698.5, 'learning_rate': 1.2e-05, 'epoch': 0.2177858439201452}\n{'loss': 0.4132, 'grad_norm': 330081.375, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.29038112522686027}\n{'loss': 0.065, 'grad_norm': 79761.6640625, 'learning_rate': 2e-05, 'epoch': 0.3629764065335753}\n{'eval_loss': 0.04624195769429207, 'eval_runtime': 236.5215, 'eval_samples_per_second': 11.648, 'eval_steps_per_second': 2.913, 'epoch': 0.3629764065335753}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0453, 'grad_norm': 127795.6171875, 'learning_rate': 1.9449187551638668e-05, 'epoch': 0.4355716878402904}\n{'loss': 0.044, 'grad_norm': 133011.171875, 'learning_rate': 1.8898375103277335e-05, 'epoch': 0.5081669691470054}\n{'loss': 0.0396, 'grad_norm': 96232.8359375, 'learning_rate': 1.8347562654916e-05, 'epoch': 0.5807622504537205}\n{'loss': 0.0383, 'grad_norm': 146381.859375, 'learning_rate': 1.7796750206554668e-05, 'epoch': 0.6533575317604355}\n{'loss': 0.038, 'grad_norm': 94047.09375, 'learning_rate': 1.7245937758193335e-05, 'epoch': 0.7259528130671506}\n{'eval_loss': 0.03343921899795532, 'eval_runtime': 236.998, 'eval_samples_per_second': 11.625, 'eval_steps_per_second': 2.907, 'epoch': 0.7259528130671506}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0394, 'grad_norm': 72417.1875, 'learning_rate': 1.6695125309832005e-05, 'epoch': 0.7985480943738656}\n{'loss': 0.0341, 'grad_norm': 77503.515625, 'learning_rate': 1.614431286147067e-05, 'epoch': 0.8711433756805808}\n{'loss': 0.032, 'grad_norm': 55145.01171875, 'learning_rate': 1.5593500413109338e-05, 'epoch': 0.9437386569872959}\n{'loss': 0.0311, 'grad_norm': 108002.703125, 'learning_rate': 1.5042687964748005e-05, 'epoch': 1.0159709618874773}\n{'loss': 0.024, 'grad_norm': 54437.828125, 'learning_rate': 1.4491875516386671e-05, 'epoch': 1.0885662431941925}\n{'eval_loss': 0.031276024878025055, 'eval_runtime': 236.1363, 'eval_samples_per_second': 11.667, 'eval_steps_per_second': 2.918, 'epoch': 1.0885662431941925}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"{'loss': 0.0238, 'grad_norm': 102351.875, 'learning_rate': 1.3941063068025338e-05, 'epoch': 1.1611615245009075}\n{'loss': 0.023, 'grad_norm': 66981.3203125, 'learning_rate': 1.3390250619664004e-05, 'epoch': 1.2337568058076225}\n{'loss': 0.0222, 'grad_norm': 71675.125, 'learning_rate': 1.2839438171302671e-05, 'epoch': 1.3063520871143375}\n{'loss': 0.0249, 'grad_norm': 259258.84375, 'learning_rate': 1.228862572294134e-05, 'epoch': 1.3789473684210527}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1f03fe3faeed>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2164\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2165\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2520\u001b[0m                     )\n\u001b[1;32m   2521\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2522\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m                     if (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3686\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3689\u001b[0m             \u001b[0;31m# Finally we need to normalize the loss for reporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2242\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2245\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"print(\"hi\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"hi\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}